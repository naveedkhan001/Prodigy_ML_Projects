{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":61155,"sourceType":"datasetVersion","datasetId":39466}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# *** *** *** *** *** *** *** *** *** PRODIGY INTERNSHIP *** *** *** *** *** *** *** *** ","metadata":{}},{"cell_type":"markdown","source":"## MACHINE_LEARNING_PROJECT_TASK# 04 :-\"HAND GESTURE RECOGNITION USING CNN\"","metadata":{}},{"cell_type":"markdown","source":"# IMPORT LIBRARIES","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nimport seaborn as sns\nimport random\n\n%matplotlib inline\nstyle.use('fivethirtyeight')\nsns.set(style='whitegrid', color_codes=True)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, roc_auc_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Activation\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam, SGD, Adagrad, Adadelta, RMSprop\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, CSVLogger, ReduceLROnPlateau\n\nimport tensorflow as tf\nimport random as rn\nimport cv2\nimport os\nfrom random import shuffle\nfrom zipfile import ZipFile\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2024-01-03T04:11:50.818423Z","iopub.execute_input":"2024-01-03T04:11:50.818761Z","iopub.status.idle":"2024-01-03T04:12:03.137081Z","shell.execute_reply.started":"2024-01-03T04:11:50.818731Z","shell.execute_reply":"2024-01-03T04:12:03.136236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DEFINE THE LABELS CORRESPONDING TO DIFFERENT GESTURES AND PREPARE THE DATASET ACCORDINGLY.","metadata":{}},{"cell_type":"code","source":"lookup = dict()\nreverselookup = dict()\ncount = 0\n\nfor j in os.listdir('../input/leapgestrecog/leapGestRecog/00/'):\n    if not j.startswith('.'):\n        lookup[j] = count\n        reverselookup[count] = j\n        count = count + 1\n\nx_data = []\ny_data = []\nIMG_SIZE = 150\ndatacount = 0\n\nfor i in range(0, 10):\n    for j in os.listdir('../input/leapgestrecog/leapGestRecog/0' + str(i) + '/'):\n        if not j.startswith('.'):\n            count = 0\n            for k in os.listdir('../input/leapgestrecog/leapGestRecog/0' + str(i) + '/' + j + '/'):\n                path = '../input/leapgestrecog/leapGestRecog/0' + str(i) + '/' + j + '/' + k\n                img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n                arr = np.array(img)\n                x_data.append(arr)\n                count = count + 1\n\n            y_values = np.full((count, 1), lookup[j])\n            y_data.append(y_values)\n            datacount = datacount + count\n\nx_data = np.array(x_data, dtype='float32')\ny_data = np.array(y_data)\ny_data = y_data.reshape(datacount, 1)","metadata":{"execution":{"iopub.status.busy":"2024-01-03T04:12:03.138591Z","iopub.execute_input":"2024-01-03T04:12:03.139151Z","iopub.status.idle":"2024-01-03T04:14:39.714602Z","shell.execute_reply.started":"2024-01-03T04:12:03.139123Z","shell.execute_reply":"2024-01-03T04:14:39.713789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print total number of files in each folder\nfor i in range(10):  # Loop over the ten top-level folders\n    folder_path = f'../input/leapgestrecog/leapGestRecog/0{i}/'\n    total_files = sum([len(files) for _, _, files in os.walk(folder_path)])\n    print(f\"Total files in {folder_path}: {total_files}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-03T04:14:39.715853Z","iopub.execute_input":"2024-01-03T04:14:39.716512Z","iopub.status.idle":"2024-01-03T04:14:39.837467Z","shell.execute_reply.started":"2024-01-03T04:14:39.716474Z","shell.execute_reply":"2024-01-03T04:14:39.836542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# VISUALIZE RANDOM SAMPLES FROM THE DATASET","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(5, 2)\nfig.set_size_inches(15, 15)\n\nfor i in range(5):\n    for j in range(2):\n        l = rn.randint(0, len(y_data))\n        ax[i, j].imshow(x_data[l])\n        ax[i, j].set_title(reverselookup[y_data[l, 0]])\n\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2024-01-03T04:14:39.839539Z","iopub.execute_input":"2024-01-03T04:14:39.839828Z","iopub.status.idle":"2024-01-03T04:14:43.197239Z","shell.execute_reply.started":"2024-01-03T04:14:39.839803Z","shell.execute_reply":"2024-01-03T04:14:43.196343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PREPROCESS THE DATA AND SPLIT INTO TRAINING AND TESTING SETS\n","metadata":{}},{"cell_type":"code","source":"y_data=to_categorical(y_data)\nx_data = x_data.reshape((datacount, IMG_SIZE, IMG_SIZE, 1))\nx_data = x_data/255","metadata":{"execution":{"iopub.status.busy":"2024-01-03T04:14:43.198436Z","iopub.execute_input":"2024-01-03T04:14:43.198731Z","iopub.status.idle":"2024-01-03T04:14:43.729018Z","shell.execute_reply.started":"2024-01-03T04:14:43.198704Z","shell.execute_reply":"2024-01-03T04:14:43.727998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train,x_test,y_train,y_test=train_test_split(x_data,y_data,test_size=0.25,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-01-03T04:14:43.730447Z","iopub.execute_input":"2024-01-03T04:14:43.730796Z","iopub.status.idle":"2024-01-03T04:14:44.250932Z","shell.execute_reply.started":"2024-01-03T04:14:43.730764Z","shell.execute_reply":"2024-01-03T04:14:44.250119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# BUILDING THE CNN MODEL ","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,1)))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n \n\nmodel.add(Conv2D(filters =96, kernel_size = (3,3),padding = 'Same',activation ='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n\nmodel.add(Conv2D(filters = 96, kernel_size = (3,3),padding = 'Same',activation ='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(Dense(10, activation = \"softmax\"))","metadata":{"execution":{"iopub.status.busy":"2024-01-03T04:14:44.252339Z","iopub.execute_input":"2024-01-03T04:14:44.252686Z","iopub.status.idle":"2024-01-03T04:14:46.840760Z","shell.execute_reply.started":"2024-01-03T04:14:44.252655Z","shell.execute_reply":"2024-01-03T04:14:46.839784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SET UP TRAINING PARAMETERS AND CALLBACKS\n","metadata":{}},{"cell_type":"code","source":"batch_size=128\nepochs=10","metadata":{"execution":{"iopub.status.busy":"2024-01-03T04:14:46.842107Z","iopub.execute_input":"2024-01-03T04:14:46.842737Z","iopub.status.idle":"2024-01-03T04:14:46.846990Z","shell.execute_reply.started":"2024-01-03T04:14:46.842699Z","shell.execute_reply":"2024-01-03T04:14:46.846131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = ModelCheckpoint(\n    './base.model',\n    monitor='val_loss',\n    verbose=1,\n    save_best_only=True,\n    mode='min',\n    save_weights_only=False,\n    period=1\n)\nearlystop = EarlyStopping(\n    monitor='val_loss',\n    min_delta=0.001,\n    patience=30,\n    verbose=1,\n    mode='auto'\n)\ntensorboard = TensorBoard(\n    log_dir = './logs',\n    histogram_freq=0,\n    batch_size=16,\n    write_graph=True,\n    write_grads=True,\n    write_images=False,\n)\n\ncsvlogger = CSVLogger(\n    filename= \"training_csv.log\",\n    separator = \",\",\n    append = False\n)\n\nreduce = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.1,\n    patience=3,\n    verbose=1, \n    mode='auto'\n)\n\ncallbacks = [checkpoint,tensorboard,csvlogger,reduce]","metadata":{"execution":{"iopub.status.busy":"2024-01-03T04:14:46.848355Z","iopub.execute_input":"2024-01-03T04:14:46.848630Z","iopub.status.idle":"2024-01-03T04:14:46.864082Z","shell.execute_reply.started":"2024-01-03T04:14:46.848607Z","shell.execute_reply":"2024-01-03T04:14:46.863331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# COMPILE THE MODEL AND DISPLAY MODEL SUMMARY\n","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer=Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-01-03T04:14:46.866426Z","iopub.execute_input":"2024-01-03T04:14:46.866705Z","iopub.status.idle":"2024-01-03T04:14:46.888012Z","shell.execute_reply.started":"2024-01-03T04:14:46.866680Z","shell.execute_reply":"2024-01-03T04:14:46.887120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-01-03T04:14:46.889231Z","iopub.execute_input":"2024-01-03T04:14:46.889589Z","iopub.status.idle":"2024-01-03T04:14:46.925723Z","shell.execute_reply.started":"2024-01-03T04:14:46.889554Z","shell.execute_reply":"2024-01-03T04:14:46.924890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TRAIN THE MODEL","metadata":{}},{"cell_type":"code","source":"History = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_test, y_test),callbacks=callbacks)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-03T04:15:35.866906Z","iopub.execute_input":"2024-01-03T04:15:35.867381Z","iopub.status.idle":"2024-01-03T04:16:54.143564Z","shell.execute_reply.started":"2024-01-03T04:15:35.867341Z","shell.execute_reply":"2024-01-03T04:16:54.142766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TRAINING AND VALIDATION GRAPH\n","metadata":{}},{"cell_type":"code","source":"plt.plot(History.history['loss'])\nplt.plot(History.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-03T04:17:42.547644Z","iopub.execute_input":"2024-01-03T04:17:42.550778Z","iopub.status.idle":"2024-01-03T04:17:42.848910Z","shell.execute_reply.started":"2024-01-03T04:17:42.550740Z","shell.execute_reply":"2024-01-03T04:17:42.847969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 4))\n\nplt.subplot(1, 2, 1)\nplt.plot(History.history['loss'], label='Training Loss')\nplt.plot(History.history['val_loss'], label='Validation Loss')\nplt.title('Training Loss vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(History.history['accuracy'], label='Training Accuracy')\nplt.plot(History.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Training Accuracy vs Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-03T04:17:47.748198Z","iopub.execute_input":"2024-01-03T04:17:47.752401Z","iopub.status.idle":"2024-01-03T04:17:48.529302Z","shell.execute_reply.started":"2024-01-03T04:17:47.752362Z","shell.execute_reply":"2024-01-03T04:17:48.528333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CONFIDENCE SCORE\n","metadata":{}},{"cell_type":"code","source":"\n# Assuming you have a function to reverse lookup the class indices\ndef reverse_lookup(index):\n    return reverselookup[index]\n\n# Select random samples from the test set\nnum_samples_to_visualize = 6\nrandom_indices = random.sample(range(len(x_test)), num_samples_to_visualize)\nx_random_samples = x_test[random_indices]\ny_random_labels = y_test[random_indices]  # Assuming y_test contains the true labels\n\n# Make predictions on the randomly selected test samples\npredictions_random = model.predict(x_random_samples)\n\n# Visualize predictions for the randomly selected test samples in 2 rows\nnum_rows = 2\nnum_cols = num_samples_to_visualize // num_rows\n\nfig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 6))\n\nfor i in range(num_rows):\n    for j in range(num_cols):\n        index = i * num_cols + j\n        # Plot the original image\n        axes[i, j].imshow(x_random_samples[index].reshape(IMG_SIZE, IMG_SIZE), cmap='gray')\n\n        # Print the confidence score in bold black color\n        predicted_class = np.argmax(predictions_random[index])\n        actual_class = np.argmax(y_random_labels[index])\n        confidence = predictions_random[index][predicted_class]\n\n        title_color = 'green' if predicted_class == actual_class else 'red'\n        axes[i, j].set_title(f'Actual: {reverse_lookup(actual_class)}\\nPredicted: {reverse_lookup(predicted_class)}\\nConfidence: {confidence:.2f}', color=title_color, backgroundcolor='white', fontsize=8, fontweight='bold')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-03T04:17:57.657765Z","iopub.execute_input":"2024-01-03T04:17:57.658511Z","iopub.status.idle":"2024-01-03T04:17:59.530664Z","shell.execute_reply.started":"2024-01-03T04:17:57.658476Z","shell.execute_reply":"2024-01-03T04:17:59.529735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CONFUSION MATRIX","metadata":{}},{"cell_type":"code","source":"y_pred = model.predict(x_test)\ny_pred_classes = np.argmax(y_pred, axis=1)\ny_true = np.argmax(y_test, axis=1)\nconf_mat = confusion_matrix(y_true, y_pred_classes)\n\nplt.figure(figsize=(10, 8))\nsns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=reverselookup.values(),\n            yticklabels=reverselookup.values())\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-03T04:18:04.507705Z","iopub.execute_input":"2024-01-03T04:18:04.508118Z","iopub.status.idle":"2024-01-03T04:18:07.051112Z","shell.execute_reply.started":"2024-01-03T04:18:04.508076Z","shell.execute_reply":"2024-01-03T04:18:07.050132Z"},"trusted":true},"execution_count":null,"outputs":[]}]}